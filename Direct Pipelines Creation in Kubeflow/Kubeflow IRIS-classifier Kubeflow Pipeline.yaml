apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: iris-classifier-kubeflow-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.20, pipelines.kubeflow.org/pipeline_compilation_time: '2023-05-04T02:13:35.436471',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "A sample pipeline that
      performs IRIS classifier task", "inputs": [{"name": "data_path", "type": "String"}],
      "name": "IRIS-classifier Kubeflow Pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.20}
spec:
  entrypoint: iris-classifier-kubeflow-pipeline
  templates:
  - name: best-metrics-model
    container:
      args: []
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'scikit-learn==1.0.2' 'mlflow==2.3.1' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'pandas==1.4.2' 'numpy==1.21.5'
        'scikit-learn==1.0.2' 'mlflow==2.3.1' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def best_metrics_model():\n    import mlflow\n    import pandas as pd\n \
        \   import numpy as np\n    import pickle\n    from sklearn.metrics import\
        \ accuracy_score,precision_score,recall_score,log_loss\n    from sklearn import\
        \ metrics\n    from sklearn.model_selection import GridSearchCV, train_test_split,\
        \ cross_val_score\n\n    mlflow.set_tracking_uri(\"http://host.docker.internal:5000\"\
        ) # Replace <minikube-ip> with your Minikube IP address\n    mlflow.set_experiment(\"\
        ml-flow-model\")\n    mlflow.end_run()\n\n        # Find the best model based\
        \ on accuracy score\n\n        # Load classifier from file\n    with open(f'data/tree_clf.pkl',\
        \ 'rb') as f:\n        tree_clf = pickle.load(f)\n\n    with open(f'data/knn_clf.pkl',\
        \ 'rb') as f:\n        knn_clf = pickle.load(f)\n\n    with open(f'data/svm_clf.pkl',\
        \ 'rb') as f:\n        svm_clf = pickle.load(f)\n\n    with open(f'data/model1.pkl','rb')\
        \ as f:\n        tree_grid_search = pickle.load(f)\n\n    with open(f'data/model2.pkl','rb')\
        \ as f:\n        knn_grid_search = pickle.load(f)\n\n    with open(f'data/model3.pkl','rb')\
        \ as f:\n        svm_grid_search = pickle.load(f)\n\n    # Load accuracy from\
        \ file\n    with open(f'data/tree_acc.pkl','rb') as f:\n        tree_acc =\
        \ pickle.load(f)\n\n    with open(f'data/SVM_acc.pkl','rb') as f:\n      \
        \  svm_acc = pickle.load(f)\n\n    with open(f'data/KNN_acc.pkl','rb') as\
        \ f:\n        knn_acc = pickle.load(f)\n\n    best_acc = max(tree_acc, knn_acc,\
        \ svm_acc)\n    best_model = None\n\n    if best_acc == tree_acc:\n      \
        \  best_model = tree_clf\n        best_params = tree_grid_search.best_params_\n\
        \    elif best_acc == knn_acc:\n        best_model = knn_clf\n        best_params\
        \ = knn_grid_search.best_params_\n    else:\n        best_model = svm_clf\n\
        \        best_params = svm_grid_search.best_params_\n\n    # Print out the\
        \ best model and its corresponding hyperparameters\n    print('best_accuracy:\
        \ ', best_acc)\n    print('best_model: ', best_model)\n    print('best_params:\
        \ ', best_params)\n\n    # Start fourth MLflow run\n    with mlflow.start_run(run_name='BEST\
        \ MODEL and MATRICES'):\n        mlflow.log_metric(\"best_accuracy\", best_acc)\n\
        \        mlflow.log_param(\"best_model\", best_model)\n        mlflow.log_params(best_params)\n\
        \        mlflow.sklearn.log_model(best_model, \"model\")\n\n    mlflow.end_run()\
        \ \n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Best metrics\
        \ model', description='')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs\
        \ = best_metrics_model(**_parsed_args)\n"
      image: python:3.9
      volumeMounts:
      - {mountPath: '{{inputs.parameters.data_path}}', name: t-vol}
    inputs:
      parameters:
      - {name: data_path}
      - {name: t-vol-name}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": [], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' ''mlflow==2.3.1'' || PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''pandas==1.4.2''
          ''numpy==1.21.5'' ''scikit-learn==1.0.2'' ''mlflow==2.3.1'' --user) && \"$0\"
          \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def best_metrics_model():\n    import mlflow\n    import
          pandas as pd\n    import numpy as np\n    import pickle\n    from sklearn.metrics
          import accuracy_score,precision_score,recall_score,log_loss\n    from sklearn
          import metrics\n    from sklearn.model_selection import GridSearchCV, train_test_split,
          cross_val_score\n\n    mlflow.set_tracking_uri(\"http://host.docker.internal:5000\")
          # Replace <minikube-ip> with your Minikube IP address\n    mlflow.set_experiment(\"ml-flow-model\")\n    mlflow.end_run()\n\n        #
          Find the best model based on accuracy score\n\n        # Load classifier
          from file\n    with open(f''data/tree_clf.pkl'', ''rb'') as f:\n        tree_clf
          = pickle.load(f)\n\n    with open(f''data/knn_clf.pkl'', ''rb'') as f:\n        knn_clf
          = pickle.load(f)\n\n    with open(f''data/svm_clf.pkl'', ''rb'') as f:\n        svm_clf
          = pickle.load(f)\n\n    with open(f''data/model1.pkl'',''rb'') as f:\n        tree_grid_search
          = pickle.load(f)\n\n    with open(f''data/model2.pkl'',''rb'') as f:\n        knn_grid_search
          = pickle.load(f)\n\n    with open(f''data/model3.pkl'',''rb'') as f:\n        svm_grid_search
          = pickle.load(f)\n\n    # Load accuracy from file\n    with open(f''data/tree_acc.pkl'',''rb'')
          as f:\n        tree_acc = pickle.load(f)\n\n    with open(f''data/SVM_acc.pkl'',''rb'')
          as f:\n        svm_acc = pickle.load(f)\n\n    with open(f''data/KNN_acc.pkl'',''rb'')
          as f:\n        knn_acc = pickle.load(f)\n\n    best_acc = max(tree_acc,
          knn_acc, svm_acc)\n    best_model = None\n\n    if best_acc == tree_acc:\n        best_model
          = tree_clf\n        best_params = tree_grid_search.best_params_\n    elif
          best_acc == knn_acc:\n        best_model = knn_clf\n        best_params
          = knn_grid_search.best_params_\n    else:\n        best_model = svm_clf\n        best_params
          = svm_grid_search.best_params_\n\n    # Print out the best model and its
          corresponding hyperparameters\n    print(''best_accuracy: '', best_acc)\n    print(''best_model:
          '', best_model)\n    print(''best_params: '', best_params)\n\n    # Start
          fourth MLflow run\n    with mlflow.start_run(run_name=''BEST MODEL and MATRICES''):\n        mlflow.log_metric(\"best_accuracy\",
          best_acc)\n        mlflow.log_param(\"best_model\", best_model)\n        mlflow.log_params(best_params)\n        mlflow.sklearn.log_model(best_model,
          \"model\")\n\n    mlflow.end_run() \n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Best
          metrics model'', description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = best_metrics_model(**_parsed_args)\n"], "image": "python:3.9"}}, "name":
          "Best metrics model"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/max_cache_staleness: P0D}
    volumes:
    - name: t-vol
      persistentVolumeClaim: {claimName: '{{inputs.parameters.t-vol-name}}'}
  - name: define-hyperparameter-and-model
    container:
      args: []
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'scikit-learn==1.0.2' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'pandas==1.4.2' 'numpy==1.21.5'
        'scikit-learn==1.0.2' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def define_hyperparameter_and_model():\n    print(\"---- Inside define_hyperparameter_and_model\
        \ component ----\")\n\n    from sklearn.model_selection import GridSearchCV,\
        \ train_test_split\n    from sklearn.tree import DecisionTreeClassifier\n\
        \    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.svm\
        \ import SVC\n    from sklearn.metrics import accuracy_score\n    import pandas\
        \ as pd\n    import io\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n\
        \    from sklearn import metrics\n    from sklearn.model_selection import\
        \ GridSearchCV, train_test_split, cross_val_score\n    import pickle\n   \
        \ import numpy as np\n\n    tree_param_grid = {'max_depth': [2, 3, 4, 5, 6,\
        \ 7, 8, 9, 10],\n                   'min_samples_split': [2, 3, 4, 5, 6, 7,\
        \ 8, 9, 10]}\n\n    knn_param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13,\
        \ 15, 17, 19],\n                      'weights': ['uniform', 'distance']}\n\
        \n    svm_param_grid = {'C': [0.1, 1, 10, 100],\n                      'kernel':\
        \ ['linear', 'poly', 'rbf', 'sigmoid']}\n\n    # Define the classifiers to\
        \ be trained\n    tree_clf = DecisionTreeClassifier(random_state=42)\n   \
        \ knn_clf = KNeighborsClassifier()\n    svm_clf = SVC(random_state=42)\n\n\
        \    # Save classifiers to file\n    with open(f'data/tree_clf.pkl', 'wb')\
        \ as f:\n        pickle.dump(tree_clf, f)    \n\n    with open(f'data/knn_clf.pkl',\
        \ 'wb') as f:\n        pickle.dump(knn_clf, f)\n\n    with open(f'data/svm_clf.pkl',\
        \ 'wb') as f:\n        pickle.dump(svm_clf, f)\n\n    # Save parameters to\
        \ file\n    with open(f'data/tree_param_grid.pkl', 'wb') as f:\n        pickle.dump(tree_param_grid,\
        \ f)\n\n    with open(f'data/knn_param_grid.pkl', 'wb') as f:\n        pickle.dump(knn_param_grid,\
        \ f)\n\n    with open(f'data/svm_param_grid.pkl', 'wb') as f:\n        pickle.dump(svm_param_grid,\
        \ f)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Define hyperparameter\
        \ and model', description='')\n_parsed_args = vars(_parser.parse_args())\n\
        \n_outputs = define_hyperparameter_and_model(**_parsed_args)\n"
      image: python:3.9
      volumeMounts:
      - {mountPath: '{{inputs.parameters.data_path}}', name: t-vol}
    inputs:
      parameters:
      - {name: data_path}
      - {name: t-vol-name}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": [], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def define_hyperparameter_and_model():\n    print(\"---- Inside define_hyperparameter_and_model
          component ----\")\n\n    from sklearn.model_selection import GridSearchCV,
          train_test_split\n    from sklearn.tree import DecisionTreeClassifier\n    from
          sklearn.neighbors import KNeighborsClassifier\n    from sklearn.svm import
          SVC\n    from sklearn.metrics import accuracy_score\n    import pandas as
          pd\n    import io\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n    from
          sklearn import metrics\n    from sklearn.model_selection import GridSearchCV,
          train_test_split, cross_val_score\n    import pickle\n    import numpy as
          np\n\n    tree_param_grid = {''max_depth'': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n                   ''min_samples_split'':
          [2, 3, 4, 5, 6, 7, 8, 9, 10]}\n\n    knn_param_grid = {''n_neighbors'':
          [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n                      ''weights'':
          [''uniform'', ''distance'']}\n\n    svm_param_grid = {''C'': [0.1, 1, 10,
          100],\n                      ''kernel'': [''linear'', ''poly'', ''rbf'',
          ''sigmoid'']}\n\n    # Define the classifiers to be trained\n    tree_clf
          = DecisionTreeClassifier(random_state=42)\n    knn_clf = KNeighborsClassifier()\n    svm_clf
          = SVC(random_state=42)\n\n    # Save classifiers to file\n    with open(f''data/tree_clf.pkl'',
          ''wb'') as f:\n        pickle.dump(tree_clf, f)    \n\n    with open(f''data/knn_clf.pkl'',
          ''wb'') as f:\n        pickle.dump(knn_clf, f)\n\n    with open(f''data/svm_clf.pkl'',
          ''wb'') as f:\n        pickle.dump(svm_clf, f)\n\n    # Save parameters
          to file\n    with open(f''data/tree_param_grid.pkl'', ''wb'') as f:\n        pickle.dump(tree_param_grid,
          f)\n\n    with open(f''data/knn_param_grid.pkl'', ''wb'') as f:\n        pickle.dump(knn_param_grid,
          f)\n\n    with open(f''data/svm_param_grid.pkl'', ''wb'') as f:\n        pickle.dump(svm_param_grid,
          f)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Define hyperparameter
          and model'', description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = define_hyperparameter_and_model(**_parsed_args)\n"], "image": "python:3.9"}},
          "name": "Define hyperparameter and model"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/max_cache_staleness: P0D}
    volumes:
    - name: t-vol
      persistentVolumeClaim: {claimName: '{{inputs.parameters.t-vol-name}}'}
  - name: get-metrics
    container:
      args: []
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'scikit-learn==1.0.2' 'mlflow==2.3.1' 'requests==2.27.1'
        || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'scikit-learn==1.0.2' 'mlflow==2.3.1' 'requests==2.27.1'
        --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def get_metrics():\n    import mlflow\n    import pandas as pd\n    import\
        \ pickle\n    import numpy as np\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n\
        \    from sklearn import metrics\n    from sklearn import metrics\n    from\
        \ sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n\
        \    import requests\n\n    print(\"---- Inside get_metrics component ----\"\
        )\n    mlflow.set_tracking_uri(\"http://host.docker.internal:5000/\")\n  \
        \  mlflow.set_experiment(\"Kubeflow-MLFlow intergration Model\")\n    mlflow.end_run()\n\
        \n    # Load the model from file   \n\n    with open(f'data/model1.pkl','rb')\
        \ as f:\n        tree_grid_search = pickle.load(f)\n\n    with open(f'data/model2.pkl','rb')\
        \ as f:\n        knn_grid_search = pickle.load(f)\n\n    with open(f'data/model3.pkl','rb')\
        \ as f:\n        svm_grid_search = pickle.load(f)\n\n    y_test = np.load(f'data/y_test.npy',allow_pickle=True)\n\
        \n    # Load the predicted model from file   \n    with open(f'data/y_pred_tree_grid_search.pkl','rb')\
        \ as f:\n        y_pred_tree_grid_search = pickle.load(f)\n\n    with open(f'data/y_pred_knn_grid_search.pkl','rb')\
        \ as f:\n        y_pred_knn_grid_search = pickle.load(f)\n\n    with open(f'data/y_pred_svm_grid_search.pkl','rb')\
        \ as f:\n        y_pred_svm_grid_search = pickle.load(f)\n\n    print(\"Decision\
        \ Tree - all metrics:\")\n    tree_scores = cross_val_score(tree_grid_search.best_estimator_,\
        \ y_test, y_pred_tree_grid_search, cv=5)\n    tree_acc_mean = tree_scores.mean()\n\
        \    tree_acc_std = tree_scores.std()\n    tree_acc = accuracy_score(y_test,\
        \ y_pred_tree_grid_search)\n    print(\"Accuracy: {:.2f}\".format(tree_acc))\n\
        \    print(\"Best hyperparameters: \", tree_grid_search.best_params_)\n\n\
        \    # Start first MLflow run\n\n    with mlflow.start_run(run_name='Decision\
        \ Tree matrices'):\n    # Log the metrics in MLFlow(Decision_Tree)\n     \
        \   mlflow.log_param(\"model\", \"Decision Tree\")\n        mlflow.log_param(\"\
        Decision_Tree_test_size\", 0.2)\n        mlflow.log_param(\"Decision_Tree_random_state\"\
        , 42)\n\n    #     mlflow.log_metric(\"Decision_Tree_tree_scores\", tree_scores)\n\
        \    #     mlflow.log_metric(\"Decision_Tree_tree_acc_mean\", tree_acc_mean)\n\
        \    #     mlflow.log_metric(\"Decision_Tree_tree_acc_std\", tree_acc_std)\n\
        \    #     mlflow.log_metric(\"Decision_Tree_r2\", r2_score(y_test, y_pred_tree_grid_search))\n\
        \n        mlflow.log_metric(\"Decision_Tree_tree_acc\", tree_acc)\n      \
        \  mlflow.log_params(tree_grid_search.best_params_)\n        #mlflow.log_metrics(metrics.classification_report(y_test,\
        \ tree_grid_search,output_dict = True))\n\n    mlflow.end_run()\n    # End\
        \ the first run\n\n    print(metrics.classification_report(y_test, y_pred_tree_grid_search,output_dict\
        \ = True))\n\n    print(\"\\nKNN - all metrics:\")\n    knn_scores = cross_val_score(tree_grid_search.best_estimator_,\
        \ y_test, y_pred_knn_grid_search, cv=5)\n    knn_acc_mean = knn_scores.mean()\n\
        \    knn_acc_std = knn_scores.std()\n    KNN_acc = accuracy_score(y_test,\
        \ y_pred_knn_grid_search)\n    print(\"Accuracy: {:.2f}\".format(KNN_acc))\n\
        \    print(\"Best hyperparameters: \", knn_grid_search.best_params_)\n\n \
        \   # Start second MLflow run\n    with mlflow.start_run(run_name='KNN matrices'):\n\
        \    # Log the metrics in MLFlow(KNN)\n        mlflow.log_param(\"model\"\
        , \"KNN\")\n        mlflow.log_param(\"KNN_test_size\", 0.2)\n\n    #    \
        \ mlflow.log_metric(\"KNN_tree_scores\", knn_scores)\n    #     mlflow.log_metric(\"\
        KNN_tree_acc_mean\", knn_acc_mean)\n    #     mlflow.log_metric(\"KNN_tree_acc_std\"\
        , knn_acc_std)\n    #     mlflow.log_metric(\"KNN_r2\", r2_score(y_test, y_pred_knn_grid_search))\n\
        \n        mlflow.log_metric(\"KNN_tree_acc\", KNN_acc)\n        mlflow.log_params(knn_grid_search.best_params_)\n\
        \        #mlflow.log_metric(\"KNN_metrics.classification_report\", metrics.classification_report(y_test,\
        \ knn_grid_search), json=True)\n    mlflow.end_run()\n    print(metrics.classification_report(y_test,\
        \ y_pred_knn_grid_search, output_dict = True))\n\n    print(\"\\nSVM - all\
        \ metrics:\")\n    svm_scores = cross_val_score(tree_grid_search.best_estimator_,\
        \ y_test, y_pred_svm_grid_search, cv=5)\n    svm_acc_mean = svm_scores.mean()\n\
        \    svm_acc_std = svm_scores.std()\n    SVM_acc = accuracy_score(y_test,\
        \ y_pred_svm_grid_search)\n    print(\"Accuracy: {:.2f}\".format(SVM_acc))\n\
        \    print(\"Best hyperparameters: \", svm_grid_search.best_params_)\n\n \
        \   with mlflow.start_run(run_name='SVM matrices'):\n    # Start third MLflow\
        \ run\n    # Log the metrics in MLFlow(SVM)\n        mlflow.log_param(\"model\"\
        , \"SVM\")\n        mlflow.log_param(\"SVM_test_size\", 0.2)\n        mlflow.log_param(\"\
        SVM_random_state\", 42)\n\n    #     mlflow.log_metric(\"SVM_tree_scores\"\
        , svm_scores)\n    #     mlflow.log_metric(\"SVM_tree_acc_mean\", svm_acc_mean)\n\
        \    #     mlflow.log_metric(\"SVM_tree_acc_std\", svm_acc_std)\n    #   \
        \  mlflow.log_metric(\"SVM_r2\", r2_score(y_test, y_pred_svm_grid_search))\n\
        \n        mlflow.log_metric(\"SVM_tree_acc\", SVM_acc)\n        mlflow.log_params(svm_grid_search.best_params_)\n\
        \        #mlflow.log_metric(\"SVM_metrics.classification_report\", metrics.classification_report(y_test,\
        \ y_pred_svm_grid_search), json=True)\n    mlflow.end_run()\n    print(metrics.classification_report(y_test,\
        \ y_pred_svm_grid_search, output_dict = True))\n\n    # Save accuracy to file\n\
        \    with open(f'data/tree_acc.pkl', 'wb') as f:\n        pickle.dump(tree_acc,\
        \ f)\n\n    with open(f'data/SVM_acc.pkl', 'wb') as f:\n        pickle.dump(SVM_acc,\
        \ f)\n\n    with open(f'data/KNN_acc.pkl', 'wb') as f:\n        pickle.dump(KNN_acc,\
        \ f)\n\n    print(metrics.classification_report(y_test, y_pred_tree_grid_search))\n\
        \    print(metrics.classification_report(y_test, y_pred_knn_grid_search))\n\
        \    print(metrics.classification_report(y_test, y_pred_svm_grid_search))\n\
        \n    mlflow.end_run()\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Get\
        \ metrics', description='')\n_parsed_args = vars(_parser.parse_args())\n\n\
        _outputs = get_metrics(**_parsed_args)\n"
      image: python:3.9
      volumeMounts:
      - {mountPath: '{{inputs.parameters.data_path}}', name: t-vol}
    inputs:
      parameters:
      - {name: data_path}
      - {name: t-vol-name}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": [], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' ''mlflow==2.3.1'' ''requests==2.27.1'' || PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''pandas==1.4.2''
          ''numpy==1.21.5'' ''scikit-learn==1.0.2'' ''mlflow==2.3.1'' ''requests==2.27.1''
          --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def get_metrics():\n    import mlflow\n    import pandas as pd\n    import
          pickle\n    import numpy as np\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n    from
          sklearn import metrics\n    from sklearn import metrics\n    from sklearn.model_selection
          import GridSearchCV, train_test_split, cross_val_score\n    import requests\n\n    print(\"----
          Inside get_metrics component ----\")\n    mlflow.set_tracking_uri(\"http://host.docker.internal:5000/\")\n    mlflow.set_experiment(\"Kubeflow-MLFlow
          intergration Model\")\n    mlflow.end_run()\n\n    # Load the model from
          file   \n\n    with open(f''data/model1.pkl'',''rb'') as f:\n        tree_grid_search
          = pickle.load(f)\n\n    with open(f''data/model2.pkl'',''rb'') as f:\n        knn_grid_search
          = pickle.load(f)\n\n    with open(f''data/model3.pkl'',''rb'') as f:\n        svm_grid_search
          = pickle.load(f)\n\n    y_test = np.load(f''data/y_test.npy'',allow_pickle=True)\n\n    #
          Load the predicted model from file   \n    with open(f''data/y_pred_tree_grid_search.pkl'',''rb'')
          as f:\n        y_pred_tree_grid_search = pickle.load(f)\n\n    with open(f''data/y_pred_knn_grid_search.pkl'',''rb'')
          as f:\n        y_pred_knn_grid_search = pickle.load(f)\n\n    with open(f''data/y_pred_svm_grid_search.pkl'',''rb'')
          as f:\n        y_pred_svm_grid_search = pickle.load(f)\n\n    print(\"Decision
          Tree - all metrics:\")\n    tree_scores = cross_val_score(tree_grid_search.best_estimator_,
          y_test, y_pred_tree_grid_search, cv=5)\n    tree_acc_mean = tree_scores.mean()\n    tree_acc_std
          = tree_scores.std()\n    tree_acc = accuracy_score(y_test, y_pred_tree_grid_search)\n    print(\"Accuracy:
          {:.2f}\".format(tree_acc))\n    print(\"Best hyperparameters: \", tree_grid_search.best_params_)\n\n    #
          Start first MLflow run\n\n    with mlflow.start_run(run_name=''Decision
          Tree matrices''):\n    # Log the metrics in MLFlow(Decision_Tree)\n        mlflow.log_param(\"model\",
          \"Decision Tree\")\n        mlflow.log_param(\"Decision_Tree_test_size\",
          0.2)\n        mlflow.log_param(\"Decision_Tree_random_state\", 42)\n\n    #     mlflow.log_metric(\"Decision_Tree_tree_scores\",
          tree_scores)\n    #     mlflow.log_metric(\"Decision_Tree_tree_acc_mean\",
          tree_acc_mean)\n    #     mlflow.log_metric(\"Decision_Tree_tree_acc_std\",
          tree_acc_std)\n    #     mlflow.log_metric(\"Decision_Tree_r2\", r2_score(y_test,
          y_pred_tree_grid_search))\n\n        mlflow.log_metric(\"Decision_Tree_tree_acc\",
          tree_acc)\n        mlflow.log_params(tree_grid_search.best_params_)\n        #mlflow.log_metrics(metrics.classification_report(y_test,
          tree_grid_search,output_dict = True))\n\n    mlflow.end_run()\n    # End
          the first run\n\n    print(metrics.classification_report(y_test, y_pred_tree_grid_search,output_dict
          = True))\n\n    print(\"\\nKNN - all metrics:\")\n    knn_scores = cross_val_score(tree_grid_search.best_estimator_,
          y_test, y_pred_knn_grid_search, cv=5)\n    knn_acc_mean = knn_scores.mean()\n    knn_acc_std
          = knn_scores.std()\n    KNN_acc = accuracy_score(y_test, y_pred_knn_grid_search)\n    print(\"Accuracy:
          {:.2f}\".format(KNN_acc))\n    print(\"Best hyperparameters: \", knn_grid_search.best_params_)\n\n    #
          Start second MLflow run\n    with mlflow.start_run(run_name=''KNN matrices''):\n    #
          Log the metrics in MLFlow(KNN)\n        mlflow.log_param(\"model\", \"KNN\")\n        mlflow.log_param(\"KNN_test_size\",
          0.2)\n\n    #     mlflow.log_metric(\"KNN_tree_scores\", knn_scores)\n    #     mlflow.log_metric(\"KNN_tree_acc_mean\",
          knn_acc_mean)\n    #     mlflow.log_metric(\"KNN_tree_acc_std\", knn_acc_std)\n    #     mlflow.log_metric(\"KNN_r2\",
          r2_score(y_test, y_pred_knn_grid_search))\n\n        mlflow.log_metric(\"KNN_tree_acc\",
          KNN_acc)\n        mlflow.log_params(knn_grid_search.best_params_)\n        #mlflow.log_metric(\"KNN_metrics.classification_report\",
          metrics.classification_report(y_test, knn_grid_search), json=True)\n    mlflow.end_run()\n    print(metrics.classification_report(y_test,
          y_pred_knn_grid_search, output_dict = True))\n\n    print(\"\\nSVM - all
          metrics:\")\n    svm_scores = cross_val_score(tree_grid_search.best_estimator_,
          y_test, y_pred_svm_grid_search, cv=5)\n    svm_acc_mean = svm_scores.mean()\n    svm_acc_std
          = svm_scores.std()\n    SVM_acc = accuracy_score(y_test, y_pred_svm_grid_search)\n    print(\"Accuracy:
          {:.2f}\".format(SVM_acc))\n    print(\"Best hyperparameters: \", svm_grid_search.best_params_)\n\n    with
          mlflow.start_run(run_name=''SVM matrices''):\n    # Start third MLflow run\n    #
          Log the metrics in MLFlow(SVM)\n        mlflow.log_param(\"model\", \"SVM\")\n        mlflow.log_param(\"SVM_test_size\",
          0.2)\n        mlflow.log_param(\"SVM_random_state\", 42)\n\n    #     mlflow.log_metric(\"SVM_tree_scores\",
          svm_scores)\n    #     mlflow.log_metric(\"SVM_tree_acc_mean\", svm_acc_mean)\n    #     mlflow.log_metric(\"SVM_tree_acc_std\",
          svm_acc_std)\n    #     mlflow.log_metric(\"SVM_r2\", r2_score(y_test, y_pred_svm_grid_search))\n\n        mlflow.log_metric(\"SVM_tree_acc\",
          SVM_acc)\n        mlflow.log_params(svm_grid_search.best_params_)\n        #mlflow.log_metric(\"SVM_metrics.classification_report\",
          metrics.classification_report(y_test, y_pred_svm_grid_search), json=True)\n    mlflow.end_run()\n    print(metrics.classification_report(y_test,
          y_pred_svm_grid_search, output_dict = True))\n\n    # Save accuracy to file\n    with
          open(f''data/tree_acc.pkl'', ''wb'') as f:\n        pickle.dump(tree_acc,
          f)\n\n    with open(f''data/SVM_acc.pkl'', ''wb'') as f:\n        pickle.dump(SVM_acc,
          f)\n\n    with open(f''data/KNN_acc.pkl'', ''wb'') as f:\n        pickle.dump(KNN_acc,
          f)\n\n    print(metrics.classification_report(y_test, y_pred_tree_grid_search))\n    print(metrics.classification_report(y_test,
          y_pred_knn_grid_search))\n    print(metrics.classification_report(y_test,
          y_pred_svm_grid_search))\n\n    mlflow.end_run()\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Get metrics'', description='''')\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = get_metrics(**_parsed_args)\n"],
          "image": "python:3.9"}}, "name": "Get metrics"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/max_cache_staleness: P0D}
    volumes:
    - name: t-vol
      persistentVolumeClaim: {claimName: '{{inputs.parameters.t-vol-name}}'}
  - name: iris-classifier-kubeflow-pipeline
    inputs:
      parameters:
      - {name: data_path}
    dag:
      tasks:
      - name: best-metrics-model
        template: best-metrics-model
        dependencies: [get-metrics, t-vol]
        arguments:
          parameters:
          - {name: data_path, value: '{{inputs.parameters.data_path}}'}
          - {name: t-vol-name, value: '{{tasks.t-vol.outputs.parameters.t-vol-name}}'}
      - name: define-hyperparameter-and-model
        template: define-hyperparameter-and-model
        dependencies: [t-vol, train-test-split]
        arguments:
          parameters:
          - {name: data_path, value: '{{inputs.parameters.data_path}}'}
          - {name: t-vol-name, value: '{{tasks.t-vol.outputs.parameters.t-vol-name}}'}
      - name: get-metrics
        template: get-metrics
        dependencies: [predict-on-test-data, t-vol]
        arguments:
          parameters:
          - {name: data_path, value: '{{inputs.parameters.data_path}}'}
          - {name: t-vol-name, value: '{{tasks.t-vol.outputs.parameters.t-vol-name}}'}
      - name: predict-on-test-data
        template: predict-on-test-data
        dependencies: [t-vol, training]
        arguments:
          parameters:
          - {name: data_path, value: '{{inputs.parameters.data_path}}'}
          - {name: t-vol-name, value: '{{tasks.t-vol.outputs.parameters.t-vol-name}}'}
      - name: prepare-data
        template: prepare-data
        dependencies: [t-vol]
        arguments:
          parameters:
          - {name: data_path, value: '{{inputs.parameters.data_path}}'}
          - {name: t-vol-name, value: '{{tasks.t-vol.outputs.parameters.t-vol-name}}'}
      - {name: t-vol, template: t-vol}
      - name: train-test-split
        template: train-test-split
        dependencies: [prepare-data, t-vol]
        arguments:
          parameters:
          - {name: data_path, value: '{{inputs.parameters.data_path}}'}
          - {name: t-vol-name, value: '{{tasks.t-vol.outputs.parameters.t-vol-name}}'}
      - name: training
        template: training
        dependencies: [define-hyperparameter-and-model, t-vol]
        arguments:
          parameters:
          - {name: data_path, value: '{{inputs.parameters.data_path}}'}
          - {name: t-vol-name, value: '{{tasks.t-vol.outputs.parameters.t-vol-name}}'}
  - name: predict-on-test-data
    container:
      args: []
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'scikit-learn==1.0.2' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'pandas==1.4.2' 'numpy==1.21.5'
        'scikit-learn==1.0.2' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def predict_on_test_data():\n    import pandas as pd\n    import numpy as\
        \ np\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n\
        \    from sklearn import metrics\n    from sklearn.model_selection import\
        \ GridSearchCV, train_test_split, cross_val_score    \n    from sklearn.linear_model\
        \ import LogisticRegression\n    from sklearn.model_selection import GridSearchCV,\
        \ train_test_split\n    from sklearn.tree import DecisionTreeClassifier\n\
        \    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.svm\
        \ import SVC\n    from sklearn.metrics import accuracy_score\n    import pickle\n\
        \n    print(\"---- Inside predict_on_test_data component ----\")\n\n    #\
        \ Loading the trained model from file\n    with open(f'data/model1.pkl','rb')\
        \ as f:\n        tree_grid_search = pickle.load(f)\n\n    with open(f'data/model2.pkl','rb')\
        \ as f:\n        knn_grid_search = pickle.load(f)\n\n    with open(f'data/model2.pkl','rb')\
        \ as f:\n        svm_grid_search = pickle.load(f)\n\n    X_test = np.load(f'data/X_test.npy',allow_pickle=True)\n\
        \n    # Predictions\n    y_pred_tree_grid_search = tree_grid_search.predict(X_test)\n\
        \    y_pred_knn_grid_search = knn_grid_search.predict(X_test)\n    y_pred_svm_grid_search\
        \ = svm_grid_search.predict(X_test)\n\n    # Save predicted model to file\n\
        \    with open(f'data/y_pred_tree_grid_search.pkl', 'wb') as f:\n        pickle.dump(y_pred_tree_grid_search,\
        \ f)\n\n    with open(f'data/y_pred_knn_grid_search.pkl', 'wb') as f:\n  \
        \      pickle.dump(y_pred_knn_grid_search, f)\n\n    with open(f'data/y_pred_svm_grid_search.pkl',\
        \ 'wb') as f:\n        pickle.dump(y_pred_svm_grid_search, f)\n\n    print(\"\
        \\n---- Predicted classes ----\")\n    print(\"\\n\")\n    print(y_pred_tree_grid_search)\n\
        \    print(y_pred_knn_grid_search)\n    print(y_pred_svm_grid_search)\n\n\
        import argparse\n_parser = argparse.ArgumentParser(prog='Predict on test data',\
        \ description='')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs =\
        \ predict_on_test_data(**_parsed_args)\n"
      image: python:3.9
      volumeMounts:
      - {mountPath: '{{inputs.parameters.data_path}}', name: t-vol}
    inputs:
      parameters:
      - {name: data_path}
      - {name: t-vol-name}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": [], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def predict_on_test_data():\n    import pandas as pd\n    import numpy
          as np\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n    from
          sklearn import metrics\n    from sklearn.model_selection import GridSearchCV,
          train_test_split, cross_val_score    \n    from sklearn.linear_model import
          LogisticRegression\n    from sklearn.model_selection import GridSearchCV,
          train_test_split\n    from sklearn.tree import DecisionTreeClassifier\n    from
          sklearn.neighbors import KNeighborsClassifier\n    from sklearn.svm import
          SVC\n    from sklearn.metrics import accuracy_score\n    import pickle\n\n    print(\"----
          Inside predict_on_test_data component ----\")\n\n    # Loading the trained
          model from file\n    with open(f''data/model1.pkl'',''rb'') as f:\n        tree_grid_search
          = pickle.load(f)\n\n    with open(f''data/model2.pkl'',''rb'') as f:\n        knn_grid_search
          = pickle.load(f)\n\n    with open(f''data/model2.pkl'',''rb'') as f:\n        svm_grid_search
          = pickle.load(f)\n\n    X_test = np.load(f''data/X_test.npy'',allow_pickle=True)\n\n    #
          Predictions\n    y_pred_tree_grid_search = tree_grid_search.predict(X_test)\n    y_pred_knn_grid_search
          = knn_grid_search.predict(X_test)\n    y_pred_svm_grid_search = svm_grid_search.predict(X_test)\n\n    #
          Save predicted model to file\n    with open(f''data/y_pred_tree_grid_search.pkl'',
          ''wb'') as f:\n        pickle.dump(y_pred_tree_grid_search, f)\n\n    with
          open(f''data/y_pred_knn_grid_search.pkl'', ''wb'') as f:\n        pickle.dump(y_pred_knn_grid_search,
          f)\n\n    with open(f''data/y_pred_svm_grid_search.pkl'', ''wb'') as f:\n        pickle.dump(y_pred_svm_grid_search,
          f)\n\n    print(\"\\n---- Predicted classes ----\")\n    print(\"\\n\")\n    print(y_pred_tree_grid_search)\n    print(y_pred_knn_grid_search)\n    print(y_pred_svm_grid_search)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Predict on test data'',
          description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = predict_on_test_data(**_parsed_args)\n"], "image": "python:3.9"}}, "name":
          "Predict on test data"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/max_cache_staleness: P0D}
    volumes:
    - name: t-vol
      persistentVolumeClaim: {claimName: '{{inputs.parameters.t-vol-name}}'}
  - name: prepare-data
    container:
      args: []
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'requests==2.27.1' 'mlflow==2.3.1' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'pandas==1.4.2' 'numpy==1.21.5'
        'requests==2.27.1' 'mlflow==2.3.1' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def prepare_data():
            import mlflow
            import pandas as pd
            import requests
            import io

            print("---- Inside prepare_data component ----")
            url = 'https://drive.google.com/uc?id=13Ebq8aiS-khJGCU6qH8xCsCbHqaJuggT'
            df = pd.read_csv(url)
            df = df.dropna()
            df.to_csv(f'data/final_df.csv', index=False)
            print("\n ---- data csv is saved to PV location /data/final_df.csv ----")

        import argparse
        _parser = argparse.ArgumentParser(prog='Prepare data', description='')
        _parsed_args = vars(_parser.parse_args())

        _outputs = prepare_data(**_parsed_args)
      image: python:3.9
      volumeMounts:
      - {mountPath: '{{inputs.parameters.data_path}}', name: t-vol}
    inputs:
      parameters:
      - {name: data_path}
      - {name: t-vol-name}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": [], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''requests==2.27.1'' ''mlflow==2.3.1'' || PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''pandas==1.4.2''
          ''numpy==1.21.5'' ''requests==2.27.1'' ''mlflow==2.3.1'' --user) && \"$0\"
          \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def prepare_data():\n    import mlflow\n    import
          pandas as pd\n    import requests\n    import io\n\n    print(\"---- Inside
          prepare_data component ----\")\n    url = ''https://drive.google.com/uc?id=13Ebq8aiS-khJGCU6qH8xCsCbHqaJuggT''\n    df
          = pd.read_csv(url)\n    df = df.dropna()\n    df.to_csv(f''data/final_df.csv'',
          index=False)\n    print(\"\\n ---- data csv is saved to PV location /data/final_df.csv
          ----\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Prepare
          data'', description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = prepare_data(**_parsed_args)\n"], "image": "python:3.9"}}, "name": "Prepare
          data"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/max_cache_staleness: P0D}
    volumes:
    - name: t-vol
      persistentVolumeClaim: {claimName: '{{inputs.parameters.t-vol-name}}'}
  - name: t-vol
    resource:
      action: create
      manifest: |
        apiVersion: v1
        kind: PersistentVolumeClaim
        metadata:
          name: '{{workflow.name}}-t-vol'
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
    outputs:
      parameters:
      - name: t-vol-manifest
        valueFrom: {jsonPath: '{}'}
      - name: t-vol-name
        valueFrom: {jsonPath: '{.metadata.name}'}
      - name: t-vol-size
        valueFrom: {jsonPath: '{.status.capacity.storage}'}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
  - name: train-test-split
    container:
      args: []
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'scikit-learn==1.0.2' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'pandas==1.4.2' 'numpy==1.21.5'
        'scikit-learn==1.0.2' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def train_test_split():
            import pandas as pd
            import numpy as np
            from sklearn.model_selection import train_test_split

            print("---- Inside train_test_split component ----")
            df = pd.read_csv(f'data/final_df.csv')
            # Split the data into features and target
            X = df.iloc[:, :-1].values
            y = df.iloc[:, -1].values

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify = y, random_state=47)

            np.save(f'data/X_train.npy', X_train)
            np.save(f'data/X_test.npy', X_test)
            np.save(f'data/y_train.npy', y_train)
            np.save(f'data/y_test.npy', y_test)

            print("\n---- X_train ----")
            print("\n")
            print(X_train)

            print("\n---- X_test ----")
            print("\n")
            print(X_test)

            print("\n---- y_train ----")
            print("\n")
            print(y_train)

            print("\n---- y_test ----")
            print("\n")
            print(y_test)

        import argparse
        _parser = argparse.ArgumentParser(prog='Train test split', description='')
        _parsed_args = vars(_parser.parse_args())

        _outputs = train_test_split(**_parsed_args)
      image: python:3.9
      volumeMounts:
      - {mountPath: '{{inputs.parameters.data_path}}', name: t-vol}
    inputs:
      parameters:
      - {name: data_path}
      - {name: t-vol-name}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": [], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def train_test_split():\n    import pandas as pd\n    import numpy as np\n    from
          sklearn.model_selection import train_test_split\n\n    print(\"---- Inside
          train_test_split component ----\")\n    df = pd.read_csv(f''data/final_df.csv'')\n    #
          Split the data into features and target\n    X = df.iloc[:, :-1].values\n    y
          = df.iloc[:, -1].values\n\n    X_train, X_test, y_train, y_test = train_test_split(X,
          y, test_size=0.2,stratify = y, random_state=47)\n\n    np.save(f''data/X_train.npy'',
          X_train)\n    np.save(f''data/X_test.npy'', X_test)\n    np.save(f''data/y_train.npy'',
          y_train)\n    np.save(f''data/y_test.npy'', y_test)\n\n    print(\"\\n----
          X_train ----\")\n    print(\"\\n\")\n    print(X_train)\n\n    print(\"\\n----
          X_test ----\")\n    print(\"\\n\")\n    print(X_test)\n\n    print(\"\\n----
          y_train ----\")\n    print(\"\\n\")\n    print(y_train)\n\n    print(\"\\n----
          y_test ----\")\n    print(\"\\n\")\n    print(y_test)\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Train test split'', description='''')\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = train_test_split(**_parsed_args)\n"],
          "image": "python:3.9"}}, "name": "Train test split"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/max_cache_staleness: P0D}
    volumes:
    - name: t-vol
      persistentVolumeClaim: {claimName: '{{inputs.parameters.t-vol-name}}'}
  - name: training
    container:
      args: []
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas==1.4.2' 'numpy==1.21.5' 'scikit-learn==1.0.2' || PIP_DISABLE_PIP_VERSION_CHECK=1
        python3 -m pip install --quiet --no-warn-script-location 'pandas==1.4.2' 'numpy==1.21.5'
        'scikit-learn==1.0.2' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def training():\n    import pandas as pd\n    import numpy as np\n    from\
        \ sklearn.linear_model import LogisticRegression\n    from sklearn.model_selection\
        \ import GridSearchCV, train_test_split\n    from sklearn.tree import DecisionTreeClassifier\n\
        \    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.svm\
        \ import SVC\n    from sklearn.metrics import accuracy_score\n    import pandas\
        \ as pd\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n\
        \    from sklearn import metrics\n    from sklearn.model_selection import\
        \ GridSearchCV, train_test_split, cross_val_score\n    import pickle\n\n \
        \   print(\"---- Inside training_basic_classifier component ----\")    \n\n\
        \    # Load parameters from file\n    with open(f'data/tree_param_grid.pkl',\
        \ 'rb') as f:\n        tree_param_grid = pickle.load(f)\n\n    with open(f'data/knn_param_grid.pkl',\
        \ 'rb') as f:\n        knn_param_grid = pickle.load(f)\n\n    with open(f'data/svm_param_grid.pkl',\
        \ 'rb') as f:\n        svm_param_grid = pickle.load(f)\n\n    # Load classifier\
        \ from file\n    with open(f'data/tree_clf.pkl', 'rb') as f:\n        tree_clf\
        \ = pickle.load(f)\n\n    with open(f'data/knn_clf.pkl', 'rb') as f:\n   \
        \     knn_clf = pickle.load(f)\n\n    with open(f'data/svm_clf.pkl', 'rb')\
        \ as f:\n        svm_clf = pickle.load(f)\n\n    # Load X_train and y_train\
        \ from file\n    X_train = np.load(f'data/X_train.npy',allow_pickle=True)\n\
        \    y_train = np.load(f'data/y_train.npy',allow_pickle=True)\n\n    # Perform\
        \ grid search with cross-validation for each classifier\n    tree_grid_search\
        \ = GridSearchCV(tree_clf, param_grid=tree_param_grid, cv=5,error_score='raise')\n\
        \    print('grid search success')\n    tree_grid_search.fit(X_train, y_train)\n\
        \    print('tree fit success')\n\n    knn_grid_search = GridSearchCV(knn_clf,\
        \ param_grid=knn_param_grid, cv=5,error_score='raise')\n    knn_grid_search.fit(X_train,\
        \ y_train)\n\n    svm_grid_search = GridSearchCV(svm_clf, param_grid=svm_param_grid,\
        \ cv=5,error_score='raise')\n    svm_grid_search.fit(X_train, y_train)\n\n\
        \    # Saving the trained model in file\n    with open(f'data/model1.pkl',\
        \ 'wb') as f:\n        pickle.dump(tree_grid_search, f)\n\n    with open(f'data/model2.pkl',\
        \ 'wb') as f:\n        pickle.dump(knn_grid_search, f)\n\n    with open(f'data/model3.pkl',\
        \ 'wb') as f:\n        pickle.dump(svm_grid_search, f)\n\n    print(\"\\n\
        \ logistic regression classifier is trained on iris data and saved to PV location\
        \ /data/model.pkl ----\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Training',\
        \ description='')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs =\
        \ training(**_parsed_args)\n"
      image: python:3.9
      volumeMounts:
      - {mountPath: '{{inputs.parameters.data_path}}', name: t-vol}
    inputs:
      parameters:
      - {name: data_path}
      - {name: t-vol-name}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.20
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": [], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3
          -m pip install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
          install --quiet --no-warn-script-location ''pandas==1.4.2'' ''numpy==1.21.5''
          ''scikit-learn==1.0.2'' --user) && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def training():\n    import pandas as pd\n    import numpy as np\n    from
          sklearn.linear_model import LogisticRegression\n    from sklearn.model_selection
          import GridSearchCV, train_test_split\n    from sklearn.tree import DecisionTreeClassifier\n    from
          sklearn.neighbors import KNeighborsClassifier\n    from sklearn.svm import
          SVC\n    from sklearn.metrics import accuracy_score\n    import pandas as
          pd\n    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n    from
          sklearn import metrics\n    from sklearn.model_selection import GridSearchCV,
          train_test_split, cross_val_score\n    import pickle\n\n    print(\"----
          Inside training_basic_classifier component ----\")    \n\n    # Load parameters
          from file\n    with open(f''data/tree_param_grid.pkl'', ''rb'') as f:\n        tree_param_grid
          = pickle.load(f)\n\n    with open(f''data/knn_param_grid.pkl'', ''rb'')
          as f:\n        knn_param_grid = pickle.load(f)\n\n    with open(f''data/svm_param_grid.pkl'',
          ''rb'') as f:\n        svm_param_grid = pickle.load(f)\n\n    # Load classifier
          from file\n    with open(f''data/tree_clf.pkl'', ''rb'') as f:\n        tree_clf
          = pickle.load(f)\n\n    with open(f''data/knn_clf.pkl'', ''rb'') as f:\n        knn_clf
          = pickle.load(f)\n\n    with open(f''data/svm_clf.pkl'', ''rb'') as f:\n        svm_clf
          = pickle.load(f)\n\n    # Load X_train and y_train from file\n    X_train
          = np.load(f''data/X_train.npy'',allow_pickle=True)\n    y_train = np.load(f''data/y_train.npy'',allow_pickle=True)\n\n    #
          Perform grid search with cross-validation for each classifier\n    tree_grid_search
          = GridSearchCV(tree_clf, param_grid=tree_param_grid, cv=5,error_score=''raise'')\n    print(''grid
          search success'')\n    tree_grid_search.fit(X_train, y_train)\n    print(''tree
          fit success'')\n\n    knn_grid_search = GridSearchCV(knn_clf, param_grid=knn_param_grid,
          cv=5,error_score=''raise'')\n    knn_grid_search.fit(X_train, y_train)\n\n    svm_grid_search
          = GridSearchCV(svm_clf, param_grid=svm_param_grid, cv=5,error_score=''raise'')\n    svm_grid_search.fit(X_train,
          y_train)\n\n    # Saving the trained model in file\n    with open(f''data/model1.pkl'',
          ''wb'') as f:\n        pickle.dump(tree_grid_search, f)\n\n    with open(f''data/model2.pkl'',
          ''wb'') as f:\n        pickle.dump(knn_grid_search, f)\n\n    with open(f''data/model3.pkl'',
          ''wb'') as f:\n        pickle.dump(svm_grid_search, f)\n\n    print(\"\\n
          logistic regression classifier is trained on iris data and saved to PV location
          /data/model.pkl ----\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Training'',
          description='''')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = training(**_parsed_args)\n"], "image": "python:3.9"}}, "name": "Training"}',
        pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/max_cache_staleness: P0D}
    volumes:
    - name: t-vol
      persistentVolumeClaim: {claimName: '{{inputs.parameters.t-vol-name}}'}
  arguments:
    parameters:
    - {name: data_path}
  serviceAccountName: pipeline-runner
