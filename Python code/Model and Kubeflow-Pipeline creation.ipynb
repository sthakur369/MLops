{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import kfp\n",
    "import kfp.components as comp\n",
    "import requests\n",
    "import kfp.dsl as dsl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Fetching and setting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import io\n",
    "    \n",
    "    print(\"---- Inside prepare_data component ----\")\n",
    "    url = 'https://drive.google.com/uc?id=13Ebq8aiS-khJGCU6qH8xCsCbHqaJuggT'\n",
    "    df = pd.read_csv(url)\n",
    "    df = df.dropna()\n",
    "    df.to_csv(f'data/final_df.csv', index=False)\n",
    "    print(\"\\n ---- data csv is saved to PV location /data/final_df.csv ----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Training and Testing data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    print(\"---- Inside train_test_split component ----\")\n",
    "    df = pd.read_csv(f'data/final_df.csv')\n",
    "    # Split the data into features and target\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify = y, random_state=47)\n",
    "    \n",
    "    np.save(f'data/X_train.npy', X_train)\n",
    "    np.save(f'data/X_test.npy', X_test)\n",
    "    np.save(f'data/y_train.npy', y_train)\n",
    "    np.save(f'data/y_test.npy', y_test)\n",
    "    \n",
    "    print(\"\\n---- X_train ----\")\n",
    "    print(\"\\n\")\n",
    "    print(X_train)\n",
    "    \n",
    "    print(\"\\n---- X_test ----\")\n",
    "    print(\"\\n\")\n",
    "    print(X_test)\n",
    "    \n",
    "    print(\"\\n---- y_train ----\")\n",
    "    print(\"\\n\")\n",
    "    print(y_train)\n",
    "    \n",
    "    print(\"\\n---- y_test ----\")\n",
    "    print(\"\\n\")\n",
    "    print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Defining the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyperparameter_and_model():\n",
    "    print(\"---- Inside define_hyperparameter_and_model component ----\")\n",
    "    \n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pandas as pd\n",
    "    import io\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    tree_param_grid = {'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                   'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "    knn_param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
    "                      'weights': ['uniform', 'distance']}\n",
    "\n",
    "    svm_param_grid = {'C': [0.1, 1, 10, 100],\n",
    "                      'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "    # Define the classifiers to be trained\n",
    "    tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    svm_clf = SVC(random_state=42)\n",
    "    \n",
    "    # Save classifiers to file\n",
    "    with open(f'data/tree_clf.pkl', 'wb') as f:\n",
    "        pickle.dump(tree_clf, f)    \n",
    "\n",
    "    with open(f'data/knn_clf.pkl', 'wb') as f:\n",
    "        pickle.dump(knn_clf, f)\n",
    "        \n",
    "    with open(f'data/svm_clf.pkl', 'wb') as f:\n",
    "        pickle.dump(svm_clf, f)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Save parameters to file\n",
    "    with open(f'data/tree_param_grid.pkl', 'wb') as f:\n",
    "        pickle.dump(tree_param_grid, f)\n",
    "        \n",
    "    with open(f'data/knn_param_grid.pkl', 'wb') as f:\n",
    "        pickle.dump(knn_param_grid, f)\n",
    "        \n",
    "    with open(f'data/svm_param_grid.pkl', 'wb') as f:\n",
    "        pickle.dump(svm_param_grid, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Traning the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "    import pickle\n",
    "    \n",
    "    print(\"---- Inside training_basic_classifier component ----\")    \n",
    "    \n",
    "    # Load parameters from file\n",
    "    with open(f'data/tree_param_grid.pkl', 'rb') as f:\n",
    "        tree_param_grid = pickle.load(f)\n",
    "        \n",
    "    with open(f'data/knn_param_grid.pkl', 'rb') as f:\n",
    "        knn_param_grid = pickle.load(f)\n",
    "        \n",
    "    with open(f'data/svm_param_grid.pkl', 'rb') as f:\n",
    "        svm_param_grid = pickle.load(f)\n",
    "    \n",
    "    # Load classifier from file\n",
    "    with open(f'data/tree_clf.pkl', 'rb') as f:\n",
    "        tree_clf = pickle.load(f)\n",
    "        \n",
    "    with open(f'data/knn_clf.pkl', 'rb') as f:\n",
    "        knn_clf = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open(f'data/svm_clf.pkl', 'rb') as f:\n",
    "        svm_clf = pickle.load(f)\n",
    "    \n",
    "    # Load X_train and y_train from file\n",
    "    X_train = np.load(f'data/X_train.npy',allow_pickle=True)\n",
    "    y_train = np.load(f'data/y_train.npy',allow_pickle=True)\n",
    "    \n",
    "\n",
    "    # Perform grid search with cross-validation for each classifier\n",
    "    tree_grid_search = GridSearchCV(tree_clf, param_grid=tree_param_grid, cv=5,error_score='raise')\n",
    "    print('grid search success')\n",
    "    tree_grid_search.fit(X_train, y_train)\n",
    "    print('tree fit success')\n",
    "\n",
    "    knn_grid_search = GridSearchCV(knn_clf, param_grid=knn_param_grid, cv=5,error_score='raise')\n",
    "    knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    svm_grid_search = GridSearchCV(svm_clf, param_grid=svm_param_grid, cv=5,error_score='raise')\n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Saving the trained model in file\n",
    "    with open(f'data/model1.pkl', 'wb') as f:\n",
    "        pickle.dump(tree_grid_search, f)\n",
    "    \n",
    "    with open(f'data/model2.pkl', 'wb') as f:\n",
    "        pickle.dump(knn_grid_search, f)\n",
    "        \n",
    "    with open(f'data/model3.pkl', 'wb') as f:\n",
    "        pickle.dump(svm_grid_search, f)\n",
    "    \n",
    "    print(\"\\n logistic regression classifier is trained on iris data and saved to PV location /data/model.pkl ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Predicting the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pickle\n",
    "    \n",
    "    print(\"---- Inside predict_on_test_data component ----\")\n",
    "    \n",
    "    # Loading the trained model from file\n",
    "    with open(f'data/model1.pkl','rb') as f:\n",
    "        tree_grid_search = pickle.load(f)\n",
    "        \n",
    "    with open(f'data/model2.pkl','rb') as f:\n",
    "        knn_grid_search = pickle.load(f)\n",
    "    \n",
    "    with open(f'data/model2.pkl','rb') as f:\n",
    "        svm_grid_search = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    \n",
    "    X_test = np.load(f'data/X_test.npy',allow_pickle=True)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_tree_grid_search = tree_grid_search.predict(X_test)\n",
    "    y_pred_knn_grid_search = knn_grid_search.predict(X_test)\n",
    "    y_pred_svm_grid_search = svm_grid_search.predict(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save predicted model to file\n",
    "    with open(f'data/y_pred_tree_grid_search.pkl', 'wb') as f:\n",
    "        pickle.dump(y_pred_tree_grid_search, f)\n",
    "        \n",
    "    with open(f'data/y_pred_knn_grid_search.pkl', 'wb') as f:\n",
    "        pickle.dump(y_pred_knn_grid_search, f)\n",
    "        \n",
    "    with open(f'data/y_pred_svm_grid_search.pkl', 'wb') as f:\n",
    "        pickle.dump(y_pred_svm_grid_search, f)\n",
    "        \n",
    "    \n",
    "    print(\"\\n---- Predicted classes ----\")\n",
    "    print(\"\\n\")\n",
    "    print(y_pred_tree_grid_search)\n",
    "    print(y_pred_knn_grid_search)\n",
    "    print(y_pred_svm_grid_search)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Getting the metrices from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    from sklearn import metrics\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "    import requests\n",
    "\n",
    "    print(\"---- Inside get_metrics component ----\")\n",
    "    mlflow.set_tracking_uri(\"http://host.docker.internal:5000/\")\n",
    "    mlflow.set_experiment(\"Kubeflow-MLFlow intergration Model\")\n",
    "    mlflow.end_run()\n",
    "    \n",
    "\n",
    "    # Load the model from file   \n",
    "\n",
    "    with open(f'data/model1.pkl','rb') as f:\n",
    "        tree_grid_search = pickle.load(f)\n",
    "\n",
    "    with open(f'data/model2.pkl','rb') as f:\n",
    "        knn_grid_search = pickle.load(f)\n",
    "\n",
    "    with open(f'data/model3.pkl','rb') as f:\n",
    "        svm_grid_search = pickle.load(f)\n",
    "\n",
    "\n",
    "    y_test = np.load(f'data/y_test.npy',allow_pickle=True)\n",
    "\n",
    "    \n",
    "    # Load the predicted model from file   \n",
    "    with open(f'data/y_pred_tree_grid_search.pkl','rb') as f:\n",
    "        y_pred_tree_grid_search = pickle.load(f)\n",
    "\n",
    "    with open(f'data/y_pred_knn_grid_search.pkl','rb') as f:\n",
    "        y_pred_knn_grid_search = pickle.load(f)\n",
    "\n",
    "    with open(f'data/y_pred_svm_grid_search.pkl','rb') as f:\n",
    "        y_pred_svm_grid_search = pickle.load(f)\n",
    "\n",
    "\n",
    "    print(\"Decision Tree - all metrics:\")\n",
    "    tree_scores = cross_val_score(tree_grid_search.best_estimator_, y_test, y_pred_tree_grid_search, cv=5)\n",
    "    tree_acc_mean = tree_scores.mean()\n",
    "    tree_acc_std = tree_scores.std()\n",
    "    tree_acc = accuracy_score(y_test, y_pred_tree_grid_search)\n",
    "    print(\"Accuracy: {:.2f}\".format(tree_acc))\n",
    "    print(\"Best hyperparameters: \", tree_grid_search.best_params_)\n",
    "\n",
    "\n",
    "    # Start first MLflow run\n",
    "\n",
    "    with mlflow.start_run(run_name='Decision Tree matrices'):\n",
    "    # Log the metrics in MLFlow(Decision_Tree)\n",
    "        mlflow.log_param(\"model\", \"Decision Tree\")\n",
    "        mlflow.log_param(\"Decision_Tree_test_size\", 0.2)\n",
    "        mlflow.log_param(\"Decision_Tree_random_state\", 42)\n",
    "\n",
    "    #     mlflow.log_metric(\"Decision_Tree_tree_scores\", tree_scores)\n",
    "    #     mlflow.log_metric(\"Decision_Tree_tree_acc_mean\", tree_acc_mean)\n",
    "    #     mlflow.log_metric(\"Decision_Tree_tree_acc_std\", tree_acc_std)\n",
    "    #     mlflow.log_metric(\"Decision_Tree_r2\", r2_score(y_test, y_pred_tree_grid_search))\n",
    "\n",
    "        mlflow.log_metric(\"Decision_Tree_tree_acc\", tree_acc)\n",
    "        mlflow.log_params(tree_grid_search.best_params_)\n",
    "        #mlflow.log_metrics(metrics.classification_report(y_test, tree_grid_search,output_dict = True))\n",
    "\n",
    "    mlflow.end_run()\n",
    "    # End the first run\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred_tree_grid_search,output_dict = True))\n",
    "\n",
    "    \n",
    "    print(\"\\nKNN - all metrics:\")\n",
    "    knn_scores = cross_val_score(tree_grid_search.best_estimator_, y_test, y_pred_knn_grid_search, cv=5)\n",
    "    knn_acc_mean = knn_scores.mean()\n",
    "    knn_acc_std = knn_scores.std()\n",
    "    KNN_acc = accuracy_score(y_test, y_pred_knn_grid_search)\n",
    "    print(\"Accuracy: {:.2f}\".format(KNN_acc))\n",
    "    print(\"Best hyperparameters: \", knn_grid_search.best_params_)\n",
    "\n",
    "    # Start second MLflow run\n",
    "    with mlflow.start_run(run_name='KNN matrices'):\n",
    "    # Log the metrics in MLFlow(KNN)\n",
    "        mlflow.log_param(\"model\", \"KNN\")\n",
    "        mlflow.log_param(\"KNN_test_size\", 0.2)\n",
    "\n",
    "    #     mlflow.log_metric(\"KNN_tree_scores\", knn_scores)\n",
    "    #     mlflow.log_metric(\"KNN_tree_acc_mean\", knn_acc_mean)\n",
    "    #     mlflow.log_metric(\"KNN_tree_acc_std\", knn_acc_std)\n",
    "    #     mlflow.log_metric(\"KNN_r2\", r2_score(y_test, y_pred_knn_grid_search))\n",
    "\n",
    "        mlflow.log_metric(\"KNN_tree_acc\", KNN_acc)\n",
    "        mlflow.log_params(knn_grid_search.best_params_)\n",
    "        #mlflow.log_metric(\"KNN_metrics.classification_report\", metrics.classification_report(y_test, knn_grid_search), json=True)\n",
    "    mlflow.end_run()\n",
    "    print(metrics.classification_report(y_test, y_pred_knn_grid_search, output_dict = True))\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"\\nSVM - all metrics:\")\n",
    "    svm_scores = cross_val_score(tree_grid_search.best_estimator_, y_test, y_pred_svm_grid_search, cv=5)\n",
    "    svm_acc_mean = svm_scores.mean()\n",
    "    svm_acc_std = svm_scores.std()\n",
    "    SVM_acc = accuracy_score(y_test, y_pred_svm_grid_search)\n",
    "    print(\"Accuracy: {:.2f}\".format(SVM_acc))\n",
    "    print(\"Best hyperparameters: \", svm_grid_search.best_params_)\n",
    "\n",
    "\n",
    "    with mlflow.start_run(run_name='SVM matrices'):\n",
    "    # Start third MLflow run\n",
    "    # Log the metrics in MLFlow(SVM)\n",
    "        mlflow.log_param(\"model\", \"SVM\")\n",
    "        mlflow.log_param(\"SVM_test_size\", 0.2)\n",
    "        mlflow.log_param(\"SVM_random_state\", 42)\n",
    "\n",
    "    #     mlflow.log_metric(\"SVM_tree_scores\", svm_scores)\n",
    "    #     mlflow.log_metric(\"SVM_tree_acc_mean\", svm_acc_mean)\n",
    "    #     mlflow.log_metric(\"SVM_tree_acc_std\", svm_acc_std)\n",
    "    #     mlflow.log_metric(\"SVM_r2\", r2_score(y_test, y_pred_svm_grid_search))\n",
    "\n",
    "        mlflow.log_metric(\"SVM_tree_acc\", SVM_acc)\n",
    "        mlflow.log_params(svm_grid_search.best_params_)\n",
    "        #mlflow.log_metric(\"SVM_metrics.classification_report\", metrics.classification_report(y_test, y_pred_svm_grid_search), json=True)\n",
    "    mlflow.end_run()\n",
    "    print(metrics.classification_report(y_test, y_pred_svm_grid_search, output_dict = True))\n",
    "\n",
    "\n",
    "\n",
    "    # Save accuracy to file\n",
    "    with open(f'data/tree_acc.pkl', 'wb') as f:\n",
    "        pickle.dump(tree_acc, f)\n",
    "\n",
    "\n",
    "\n",
    "    with open(f'data/SVM_acc.pkl', 'wb') as f:\n",
    "        pickle.dump(SVM_acc, f)\n",
    "\n",
    "\n",
    "    with open(f'data/KNN_acc.pkl', 'wb') as f:\n",
    "        pickle.dump(KNN_acc, f)\n",
    "\n",
    "\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred_tree_grid_search))\n",
    "    print(metrics.classification_report(y_test, y_pred_knn_grid_search))\n",
    "    print(metrics.classification_report(y_test, y_pred_svm_grid_search))\n",
    "\n",
    "    mlflow.end_run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Finding the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_metrics_model():\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://host.docker.internal:5000\") # Replace <minikube-ip> with your Minikube IP address\n",
    "    mlflow.set_experiment(\"Kubeflow-MLFlow intergration Model\")\n",
    "    mlflow.end_run()\n",
    "\n",
    "        # Find the best model based on accuracy score\n",
    "\n",
    "        # Load classifier from file\n",
    "    with open(f'data/tree_clf.pkl', 'rb') as f:\n",
    "        tree_clf = pickle.load(f)\n",
    "\n",
    "    with open(f'data/knn_clf.pkl', 'rb') as f:\n",
    "        knn_clf = pickle.load(f)\n",
    "\n",
    "\n",
    "    with open(f'data/svm_clf.pkl', 'rb') as f:\n",
    "        svm_clf = pickle.load(f)\n",
    "\n",
    "\n",
    "    with open(f'data/model1.pkl','rb') as f:\n",
    "        tree_grid_search = pickle.load(f)\n",
    "\n",
    "    with open(f'data/model2.pkl','rb') as f:\n",
    "        knn_grid_search = pickle.load(f)\n",
    "\n",
    "    with open(f'data/model3.pkl','rb') as f:\n",
    "        svm_grid_search = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "    # Load accuracy from file\n",
    "    with open(f'data/tree_acc.pkl','rb') as f:\n",
    "        tree_acc = pickle.load(f)\n",
    "\n",
    "    with open(f'data/SVM_acc.pkl','rb') as f:\n",
    "        svm_acc = pickle.load(f)\n",
    "\n",
    "    with open(f'data/KNN_acc.pkl','rb') as f:\n",
    "        knn_acc = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    best_acc = max(tree_acc, knn_acc, svm_acc)\n",
    "    best_model = None\n",
    "\n",
    "    if best_acc == tree_acc:\n",
    "        best_model = tree_clf\n",
    "        best_params = tree_grid_search.best_params_\n",
    "    elif best_acc == knn_acc:\n",
    "        best_model = knn_clf\n",
    "        best_params = knn_grid_search.best_params_\n",
    "    else:\n",
    "        best_model = svm_clf\n",
    "        best_params = svm_grid_search.best_params_\n",
    "\n",
    "    # Print out the best model and its corresponding hyperparameters\n",
    "    print('best_accuracy: ', best_acc)\n",
    "    print('best_model: ', best_model)\n",
    "    print('best_params: ', best_params)\n",
    "\n",
    "\n",
    "    # Start fourth MLflow run\n",
    "    with mlflow.start_run(run_name='BEST MODEL and MATRICES'):\n",
    "        mlflow.log_metric(\"best_accuracy\", best_acc)\n",
    "        mlflow.log_param(\"best_model\", best_model)\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.sklearn.log_model(best_model, \"model\")\n",
    "\n",
    "    mlflow.end_run() \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubeflow 7 Pipelines creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_prepare_data = kfp.components.create_component_from_func(\n",
    "    func=prepare_data,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['pandas==1.4.2','numpy==1.21.5','requests==2.27.1','mlflow==2.3.1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_train_test_split = kfp.components.create_component_from_func(\n",
    "    func=train_test_split,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['pandas==1.4.2','numpy==1.21.5','scikit-learn==1.0.2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_define_hyperparameter_and_model = kfp.components.create_component_from_func(\n",
    "    func=define_hyperparameter_and_model,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['pandas==1.4.2','numpy==1.21.5','scikit-learn==1.0.2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_training = kfp.components.create_component_from_func(\n",
    "    func=training,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['pandas==1.4.2','numpy==1.21.5','scikit-learn==1.0.2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_predict_on_test_data = kfp.components.create_component_from_func(\n",
    "    func=predict_on_test_data,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['pandas==1.4.2','numpy==1.21.5','scikit-learn==1.0.2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_get_metrics = kfp.components.create_component_from_func(\n",
    "    func=get_metrics,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['pandas==1.4.2','numpy==1.21.5','scikit-learn==1.0.2','mlflow==2.3.1','requests==2.27.1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_best_metrics_model = kfp.components.create_component_from_func(\n",
    "    func=best_metrics_model,\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['pandas==1.4.2','numpy==1.21.5','scikit-learn==1.0.2','mlflow==2.3.1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='IRIS-classifier Kubeflow Pipeline',\n",
    "   description='A sample pipeline that performs IRIS classifier task'\n",
    ")\n",
    "# Define parameters to be fed into pipeline\n",
    "def iris_classifier_pipeline(data_path: str):\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"t-vol\",\n",
    "    resource_name=\"t-vol\", \n",
    "    size=\"1Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "  #  Setting the priority\n",
    "    prepare_data_task = create_step_prepare_data().add_pvolumes({data_path: vop.volume})\n",
    "    train_test_split = create_step_train_test_split().add_pvolumes({data_path: vop.volume}).after(prepare_data_task)\n",
    "    define_hyperparameter_and_model = create_define_hyperparameter_and_model().add_pvolumes({data_path: vop.volume}).after(train_test_split)\n",
    "\n",
    "    training = create_step_training().add_pvolumes({data_path: vop.volume}).after(define_hyperparameter_and_model)\n",
    "    log_predicted_class = create_step_predict_on_test_data().add_pvolumes({data_path: vop.volume}).after(training)\n",
    "    log_metrics_task = create_step_get_metrics().add_pvolumes({data_path: vop.volume}).after(log_predicted_class)\n",
    "    log_best_metrics_task = create_step_best_metrics_model().add_pvolumes({data_path: vop.volume}).after(log_metrics_task)\n",
    "\n",
    "    #setting caching config\n",
    "    prepare_data_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    train_test_split.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    define_hyperparameter_and_model.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    training.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    log_predicted_class.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    log_metrics_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    log_best_metrics_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and starting the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=iris_classifier_pipeline,\n",
    "    package_path='IRIS-classifier Kubeflow Pipeline.yaml')\n",
    "\n",
    "#Start\n",
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/11e92289-dd5d-4c50-afb0-d65658f93bc6\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/693827db-d073-4094-9128-e0e6cd16cf4f\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_PATH = '/data'\n",
    "\n",
    "import datetime\n",
    "print(datetime.datetime.now().date())\n",
    "\n",
    "\n",
    "pipeline_func = iris_classifier_pipeline\n",
    "experiment_name = 'iris_classifier_exp' +\"_\"+ str(datetime.datetime.now().date())\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "namespace = \"kubeflow\"\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH}\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "  '{}.zip'.format(experiment_name))\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
